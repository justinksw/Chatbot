{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('python38-tensor': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b141fec0f123f1714c0abae9c6fe5b6241fbf32498a8ec5d7a34fb2b79b23d31"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import Packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "# nltk.download('punkt')\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "source": [
    "## Load data from intents.json\n",
    "1. Get all words for preparing bag of words (BOW).\n",
    "2. Get all intents for checking prediction results.\n",
    "3. words and intents are in sorted order as model training process."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "words = []  # store all words in data\n",
    "intents = []  # store classes of intents\n",
    "words_to_ignore = ['?', '.']\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        words_each_pattern = nltk.word_tokenize(pattern)  # split the sentence\n",
    "        words.extend(words_each_pattern)  # w is a list\n",
    "\n",
    "    if intent['tag'] not in intents:\n",
    "        intents.append(intent['tag'])\n",
    "\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in words_to_ignore]\n",
    "\n",
    "words = sorted(list(set(words)))\n",
    "intents = sorted(list(set(intents)))"
   ]
  },
  {
   "source": [
    "## Load saved model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "source": [
    "## chat function for utilizing the model\n",
    "### Parameter: sentence(string)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(sentence):\n",
    "    # Prepare bag of words:\n",
    "    bag = []\n",
    "\n",
    "    words_in_sentence = nltk.word_tokenize(sentence)\n",
    "    words_in_sentence = [stemmer.stem(w.lower()) for w in words_in_sentence]\n",
    "\n",
    "    for w in words:\n",
    "        if w in words_in_sentence:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "    \n",
    "    # Format bag for trained model\n",
    "    bag = pd.DataFrame([bag])\n",
    "\n",
    "    # Make predictions\n",
    "    results = model.predict(bag)[0]\n",
    "    results_index = np.argmax(results)  # Choose one with highest probability\n",
    "\n",
    "    intent = intents[results_index]\n",
    "\n",
    "    if results[results_index] > 0.8:\n",
    "        for tg in data[\"intents\"]:\n",
    "            if tg['tag'] == intent:\n",
    "                responses = tg['responses']\n",
    "        print(random.choice(responses))  # Randomly choose one response\n",
    "    else:\n",
    "        print(\"I didnt understander. Try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "chat('is anyone here?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I'm Justin.\n"
     ]
    }
   ],
   "source": [
    "chat('how can i call you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I am a fast and self-motivated learner.\n"
     ]
    }
   ],
   "source": [
    "chat('can you tell me something about yourself?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I obtained a BEng in Mechanical and Automation Engineering from CUHK.\n"
     ]
    }
   ],
   "source": [
    "chat('I want to know your education background')"
   ]
  }
 ]
}